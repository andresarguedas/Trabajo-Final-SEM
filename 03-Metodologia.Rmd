\subsection{Generación de datos con kurtosis}

Los datos fueron simulados mediante la función `simulateData()` del paquete `lavaan` [@lavaan], el cual utiliza el método propuesto por @Vale1983 para la simulación de datos no normales multivariados. Este método, comúnmente conocido como VM, se basa en el método propuesto por @Fleishman1978, el cual, con base en una variable aleatoria distribuida como una normal estándar, permite simular una variable con un promedio, variancia, asimetría y kurtosis dada. El método VM permite especificar, adicionalmente, correlaciones entre las variables a estimar. Para utilizar el método de Fleishman, para generar una cierta variable aleatoria $Y$, se utiliza la siguiente ecuación:

\begin{equation} \label{eq:defY}
  Y = a + bX + cX^2 + d X^3
\end{equation}

donde $X \sim \mathcal{N} (0,1)$. Es decir, se puede generar una variable no normal $Y$, con sus primeros cuatro momentos iguales a valores especificados, con base en los valores $a$, $b$, $c$ y $d$ de la ecuación \ref{eq:defY}, con base en una variable normal estándar $X$ hasta su tercer potencia. Luego, para poder obtener los valores de $a$, $b$, $c$ y $d$, se necesitan resolver las siguientes ecuaciones de forma simultánea:

\begin{align*}
  b^2 + 6bd + 2c^2 + 15d^2 -1 & = 0 \\
  2c (b^2 + 24bd + 105d^2 + 2) - \gamma_1 & = 0 \\
  24 \left(bd + c^2 (1 + b^2 + 28bd) + d^2 (12 + 48bd + 141c^2 + 225d^2) \right) - \gamma_2 & = 0
\end{align*}

donde $\gamma_1$ es la asimetría deseada y $\gamma_2$ es la kurtosis deseada, además se define $a = -c$. Con base en las constantes calculadas $a$, $b$, $c$ y $d$, además de una variable normal estándar, se puede simular variables no normales. Para poder generalizar el método de Fleishman a variables aleatorias multivariantes, Vale y Maurelli proponen una generalización. Esta se basa, para el caso bivariado, en la generación de dos variables aleatorias independientes, $X_1, X_2 \sim \mathcal{N} (0,1)$, para la cuales se obtienen las constantes $a$, $b$, $c$ y $d$, para cada una de dichas variables, como se describe en el método de Fleishman, obteniendo así el vector $w^\prime_1 = (a_1, b_1, c_1, d_1)$, para el caso de $X_1$, y el vector $w^\prime_2 = (a_2, b_2, c_2, d_2)$, para el caso de $X_2$. Además, se definen los vectores $x_1^\prime = (1, X_1, X_1^2, X_1^3)$ y $x_2^\prime = (1, X_2, X_2^2, X_2^3)$. Por lo tanto, se pueden crear variables no normales, $Y_1$ y $Y_2$, como:

\begin{align*}
  Y_1 & = w_1^\prime x_1 \\
  Y_2 & = w_2^\prime x_2
\end{align*}

donde se puede verificar que:

\begin{align*}
  r_{Y_1, Y_2} = & \rho_{X_1, X_2} (b_1 b_2 + 3b_1 d_2 + 3d_1 b_2 + 9 d_1 d_2) \\
  & + \rho_{X_1, X_2}^2 (2 c_1 c_2) + \rho_{X_1, X_2}^3 (6 d_1 d_2)
\end{align*}

Y resolviendo esta ecuación en términos de $\rho_{X_1, X_2}$ se puede obtener una matriz de correlaciones para generar datos normales multivariados, que pueden ser transformados en variables no normales mediante el método de Fleishman.

\subsection{Modelo a estimar}

El modelo teórico utilizada para realizar las simulaciones es el presentado por @SuraFonseca2020, basado en datos de 155 estudiantes de la Universidad de Costa Rica, obtenidos de la Prueba de Habilidades Cuantitativas (PHC) del Instituto de Investigaciones Psicológicos (IIP) de dicha universidad y de un cuestionario autoadministrado aplicado a estos estudiantes. El modelo estimado está compuesto por dos variables exógenas (capital y habilidades cuantitativas) y una variable endógena (habilidades visoespaciales). Con respecto a estas variables: el capital se refiere al acceso y tenencia de ciertos bienes en los hogares de los estudiantes; las habilidades cuantitativas se refieren a la puntuación de los estudiantes en la prueba mencionada anteriormente; y las habilidades visoespaciales se refieren a la capacidad de los estudiantes para poder trabajar con objetos tridimensionales abstractos y poder manipularlos en la imaginación. Para cada una de estas variables latentes, se utilizó el método de parcelas para obtener tres variables indicadoras para cada uno de los constructos. Los resultados de la estimación de dicho modelo, presentados por @SuraFonseca2020, se presentan en la Figura \ref{fig:mod_teorico}.

\begin{figure}[!h]
\centering
\caption{Modelo estimado sobre las habilidades cuantitativas}
\label{fig:mod_teorico}
\begin{tikzpicture}
        [
    basic/.style={draw, text centered},
    circ/.style={basic, circle, minimum size=2em, inner sep=1.5pt},
    rect/.style={basic, text height=1em, text depth=.5em, minimum width=1.5em},
    >={Stealth[]}
    ]

    % Variables latentes
    \node [circ] (ve) {VE};
    \node [circ, above left=1.5cm and 1cm of ve] (ca) {CA};
    \node [circ, below left=1.5cm and 1cm of ve] (phc) {PHC};
    \draw [->] (ca) -- node[fill=white] {-0.01} (ve);
    \draw [->] (phc) -- node[fill=white] {0.41} (ve);
    % Variancia de VE
    \node [left=of ve] (delta) {0.83};
    \draw [->] (delta) -- (ve);
    % Variables indicadoras de VE
    \node [rect, above right=1cm and 2cm of ve.center] (pve1) {PVE1};
    \node [rect, right=2cm of ve.center] (pve2) {PVE2};
    \node [rect, below right=1cm and 2cm of ve.center] (pve3) {PVE3};
    \draw [->] (ve) -- node[fill=white] {0.62} (pve1.west);
    \draw [->] (ve) -- node[fill=white] {0.74} (pve2.west);
    \draw [->] (ve) -- node[fill=white] {0.72} (pve3.west);
    % Variancia de variables indicadoras de VE
    \node [right=of pve1] (epve1) {0.62};
    \node [right=of pve2] (epve2) {0.45};
    \node [right=of pve3] (epve3) {0.48};
    \draw [->] (epve1) -- (pve1);
    \draw [->] (epve2) -- (pve2);
    \draw [->] (epve3) -- (pve3);
    % Variables indicadoras de CA
    \node [rect, above left=1cm and 2cm of ca.center] (pc1) {PC1};
    \node [rect, left=2cm of ca.center] (pc2) {PC2};
    \node [rect, below left=1cm and 2cm of ca.center] (pc3) {PC3};
    \draw [->] (ca) -- node[fill=white] {0.88} (pc1.east);
    \draw [->] (ca) -- node[fill=white] {0.77} (pc2.east);
    \draw [->] (ca) -- node[fill=white] {0.73} (pc3.east);
    % Variancia de variables indicadoras de CA
    \node [left=of pc1] (epc1) {0.22};
    \node [left=of pc2] (epc2) {0.41};
    \node [left=of pc3] (epc3) {0.47};
    \draw [->] (epc1) -- (pc1);
    \draw [->] (epc2) -- (pc2);
    \draw [->] (epc3) -- (pc3);
    % Variables indicadoras de PHC
    \node [rect, above left=1cm and 2cm of phc.center] (phc1) {PHC1};
    \node [rect, left=2cm of phc.center] (phc2) {PHC2};
    \node [rect, below left=1cm and 2cm of phc.center] (phc3) {PHC3};
    \draw [->] (phc) -- node[fill=white] {0.85} (phc1.east);
    \draw [->] (phc) -- node[fill=white] {0.80} (phc2.east);
    \draw [->] (phc) -- node[fill=white] {0.82} (phc3.east);
    % Variancia de variables indicadoras de CA
    \node [left=of phc1] (ephc1) {0.28};
    \node [left=of phc2] (ephc2) {0.37};
    \node [left=of phc3] (ephc3) {0.33};
    \draw [->] (ephc1) -- (phc1);
    \draw [->] (ephc2) -- (phc2);
    \draw [->] (ephc3) -- (phc3);
\end{tikzpicture}
\end{figure}

\subsection{Simulación y estimación}

La simulación de los datos, junto con la estimación de los modelos, se realizó mediante el paquete `lavaan` [@lavaan] usando el software R [@R] mediante la interfaz gráfica de RStudio [@RStudio]. Para el manejo de bases de datos y demás visualizaciones fueron utilizados los paquetes `ggplot2`[@ggplot2], `tidyr` [@tidyr], `dplyr` [@dplyr], `ggpubr` [@ggpubr], `PerformanceAnalytics` [@PerformanceAnalytics] y `kableExtra` [@kableExtra].

Para poder realizar la simulación deben seguirse varios pasos. Lo primero es definir el modelo teórico poblacional que van a seguir los datos simulados, como se describió en la sección anterior este modelo cuenta con dos variables exógenas y una endógena, cada una con tres variables indicadoras. Los datos se generan mediante la función `simulateData()` la cuál requiere especificar varios argumentos, uno de ellos es el modelo poblacional. Los otros dos argumentos a especificar son el tamaño de muestra deseado y el nivel de kurtosis de interés, la definición de estos escenarios se muestran en el cuadro \ref{tab:escenarios}:

```{r, echo=FALSE}
cuadro <- expand.grid(kurtosis=c(0, 0.62, 6.65, 21.41, 13.92), n=c(50, 100, 120, 200, 300))

cbind(cuadro[1:5,], cuadro[6:10,], cuadro[11:15,], cuadro[16:20,], cuadro[21:25,]) %>% 
  kable(., "latex", booktabs=T,caption="\\label{tab:escenarios}Escenarios de simulación") %>% 
footnote(general = "Elaboración propia a partir del estudio de la Universidad de California (2008)", general_title = "Fuente:", title_format = "italic",
         footnote_as_chunk = T) %>% 
    kable_styling(latex_options = c("striped", "scale_down", "repeat_header", "hold_position"), repeat_header_text = "(cont.)", font_size = 9,full_width = T) 
```

Con estos escenarios definidos, se generaron entonces, para cada combinación de tamaño de muestra y kurtosis un total de 2000 conjuntos de datos para cada uno. Una vez que se obtuvieron estos conjuntos de datos, el siguiente paso es realizar la estimación de los SEM con cada uno de ellos; para ello es necesario definir un modelo sin los valores de las cargas factoriales, pues se busca conocer las estimaciones a partir de los datos generados.

\subsection{Medidas de bondad de ajuste}

Las medidas de bondad de ajuste utilizadas para comparar el ajuste de los modelos, para cada uno de los escenarios de simulación son: el estadístico chi-cuadrado, el RMSEA, el SRMR y el CFI.

\subsubsection{Estadístico chi-cuadrado}

El estadístico de chi-cuadrado busca cuantificar la diferencia que se presenta entre la matriz de covariancias de una muestra con la matriz de covariancias estimadas mediante un cierto modelo. Según @Hu1999, su fórmula de cálculo viene dada por:
\[
  \chi^2 = (N-1) F_{min}
\]
donde $N$ es el tamaño de la muestra y $F_{min}$ es el mínimo obtenido mediante la función de ajuste, la cual, normalmente, se asume que es la distribución normal multivariada, utilizando el método de máxima verosimilitud. Este estadístico tiene una distribución chi-cuadrado con grados de libertad igual a la cantidad de piezas de información única en la matriz de covariancias menos la cantidad de parámetros a estimar del modelo, bajo el supuesto de normalidad y, si este supuesto no se cumple, la distribución asintótica sigue siendo una chi-cuadrado con esos mismos grados de libertad. El estadístico chi-cuadrado es muy utilizado en los modelos de ecuaciones estructurales y da origen a la gran mayoría de las demás medidas de ajuste utilizadas en dichos modelos, aunque puede presentar algunos problemas ya que depende del tamaño de la muestra, por lo que, con muestras grandes tiende a ser significativo, mientras que con muestras pequeños tiende a no ser significativo [@Kenny2015].

\subsubsection{RMSEA}

El Error Cuadrático Medio de Aproximación (RMSEA por sus siglas en inglés) es una de las medidas de ajuste más conocidas y utilizadas en los modelos de ecuaciones estructurales. Su fórmula, según @Hu1999, viene dada por:
\[
  RMSEA = \sqrt{\max\left\{\frac{\chi^2 - gl}{gl (N-1)} , 0 \right\}}
\]
donde $\chi^2$ es el valor de la chi-cuadrado, $gl$ son los grados de libertad, y $N$ es el tamaño de la muestra. Por lo general, se considera un valor del RMSEA menor a 0.05 como un indicador de un buen ajuste, mientras que un valor mayor a 0.1 representa un mal ajuste del modelo [@Kenny2015].

\subsubsection{SRMR}

La Raíz Estandarizada del Error Cuadrático Medio (SRMR por sus siglas en inglés) es una medida de ajuste en la cual se comparan las diferencias entre las covariancias estimadas y las de la muestra. La fórmula de cálculo, con base en @Hu1999 es:
\[
  SRMR = \sqrt{\left(2 \sum\limits_{i=1}^p \sum\limits_{j=1}^i \left((s_{ij} - \hat\sigma_{ij}) / (s_{ii} s_{jj}) \right)^2 \right)^2 / p(p+1)}
\]
donde $p$ es el número de variables observadas, $s_{ij}$ son las covariancias observadas y $\hat\sigma_{ij}$ son las covariancias estimadas de las variables $i$ y $j$. Dado que se están comparando las covariancias observadas y las estimadas, un valor de 0 indica un ajuste perfecto del modelo, pero, por lo general, se considera un valor menor a 0.08 como un indicador de un buen ajuste [@Kenny2015].

\subsubsection{CFI}

El Índice de Ajuste Comparativo (CFI por sus siglas en inglés) es una medida de ajuste que compara el valor de chi-cuadrado del modelo estimado con el valor de chi-cuadrado del modelo nulo, agregando una penalización por la cantidad de parámetros estimados. La fórmula de cálculo presentada por @Hu1999 es la siguiente:
\[
  CFI = 1 - \left( \frac{\max \left\{(\chi^2_T - gl_T), 0  \right\}}{\max \left\{(\chi^2_T - gl_T), (\chi^2_N - gl_N), 0 \right\}} \right)
\]
donde $\chi^2_T$ y $\chi^2_N$ son los valores del estadístico chi-cuadrado para el modelo estimado y el nulo, respectivamente, y $gl_T$ y $gl_N$ son los grados de libertad de los modelos estimado y nulo, respectivamente. Esta medida de ajuste puede tomar un valor entre 0 y 1 y se considera que el modelo tiene un buen ajuste cuando es mayor a 0.95, un buen ajuste cuando el valor está entre 0.9 y 0.95 y un mal ajuste cuando es menor que 0.9 [@Kenny2015].
